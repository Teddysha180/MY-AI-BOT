import telebot
import os
import json
import logging
import requests
from datetime import datetime
from groq import Groq
from telebot.types import InlineKeyboardMarkup, InlineKeyboardButton
import sqlite3
import threading
import traceback
import time
import base64
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# ============================================================================
# ğŸš€ CONFIGURATION
# ============================================================================
BOT_TOKEN = os.getenv("BOT_TOKEN")
GROQ_KEY = os.getenv("GROQ_API_KEY")
HF_KEY = os.getenv("HF_API_KEY")

# Initialize clients with safer handling so the module can run without keys
groq_client = None
bot = None

if GROQ_KEY:
    try:
        groq_client = Groq(api_key=GROQ_KEY)
    except Exception as e:
        print(f"âš ï¸ Groq client init warning: {e}")
        logger = logging.getLogger(__name__)
        logger.warning(f"Groq client init failed: {e}")
        groq_client = None
else:
    print("âš ï¸ GROQ_API_KEY not set; Groq features disabled.")

if BOT_TOKEN:
    try:
        bot = telebot.TeleBot(BOT_TOKEN, parse_mode="Markdown")
    except Exception as e:
        print(f"âš ï¸ Telegram bot init warning: {e}")
        logger = logging.getLogger(__name__)
        logger.warning(f"Telegram bot init failed: {e}")
        bot = None
else:
    print("âš ï¸ BOT_TOKEN not set; Telegram bot disabled. Set BOT_TOKEN in .env to enable.")

# If bot couldn't be initialized (missing token or init error), provide a lightweight
# dummy object with the decorator APIs used in this module so importing/running the
# script won't fail at the @bot.message_handler / @bot.callback_query_handler lines.
if not bot:
    class _DummyBot:
        def message_handler(self, *args, **kwargs):
            def decorator(func):
                return func
            return decorator

        def callback_query_handler(self, *args, **kwargs):
            def decorator(func):
                return func
            return decorator

        # Basic methods used across the code. They are no-ops when the real bot
        # isn't available.
        def send_message(self, *args, **kwargs):
            print("[DummyBot] send_message called; BOT_TOKEN not configured.")
            return None

        def send_photo(self, *args, **kwargs):
            print("[DummyBot] send_photo called; BOT_TOKEN not configured.")
            return None

        def delete_message(self, *args, **kwargs):
            return None

        def get_file(self, *args, **kwargs):
            raise RuntimeError("DummyBot: no file support when BOT_TOKEN is not set")

        def download_file(self, *args, **kwargs):
            raise RuntimeError("DummyBot: no download support when BOT_TOKEN is not set")

        def send_chat_action(self, *args, **kwargs):
            return None

        def edit_message_text(self, *args, **kwargs):
            return None

        def answer_callback_query(self, *args, **kwargs):
            return None

        def get_me(self):
            return type("Me", (), {"username": "(disabled_bot)"})

        def infinity_polling(self, *args, **kwargs):
            print("[DummyBot] infinity_polling skipped: BOT_TOKEN not configured.")

    bot = _DummyBot()

# ============================================================================
# ğŸ“Š LOGGING & ANALYTICS
# ============================================================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(name)s | %(message)s',
    handlers=[
        logging.FileHandler('artovix.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class Analytics:
    def __init__(self):
        self.conn = sqlite3.connect('analytics.db', check_same_thread=False)
        self.lock = threading.Lock()
        self._init_db()
        
    def _init_db(self):
        cursor = self.conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                tokens INTEGER DEFAULT 0,
                request_type TEXT
            )
        ''')
        self.conn.commit()
    
    def log_request(self, user_id: str, tokens: int, request_type: str):
        try:
            with self.lock:
                cursor = self.conn.cursor()
                cursor.execute('''
                    INSERT INTO metrics (user_id, tokens, request_type)
                    VALUES (?, ?, ?)
                ''', (str(user_id), tokens, request_type))
                self.conn.commit()
        except Exception as e:
            logger.error(f"Analytics log error: {e}")
    
    def get_current_metrics(self):
        try:
            with self.lock:
                cursor = self.conn.cursor()
                
                cursor.execute('''
                    SELECT COUNT(*) FROM metrics 
                    WHERE timestamp > datetime('now', '-1 minute')
                ''')
                rpm = cursor.fetchone()[0] or 0
                
                cursor.execute('''
                    SELECT SUM(tokens) FROM metrics 
                    WHERE timestamp > datetime('now', '-1 minute')
                ''')
                tpm_result = cursor.fetchone()[0]
                tpm = tpm_result if tpm_result else 0
                
                cursor.execute('''
                    SELECT COUNT(*) FROM metrics 
                    WHERE DATE(timestamp) = DATE('now')
                ''')
                rpd = cursor.fetchone()[0] or 0
                
                # Per-type breakdown for today
                cursor.execute('''
                    SELECT request_type, COUNT(*) FROM metrics 
                    WHERE DATE(timestamp) = DATE('now')
                    GROUP BY request_type
                ''')
                breakdown = dict(cursor.fetchall())
                
                return {"RPM": rpm, "TPM": tpm, "RPD": rpd, "breakdown": breakdown}
        except Exception as e:
            logger.error(f"Analytics metrics error: {e}")
            return {"RPM": 0, "TPM": 0, "RPD": 0, "breakdown": {}}
    
    def close(self):
        try:
            with self.lock:
                self.conn.close()
        except:
            pass

analytics = Analytics()

# ============================================================================
# ğŸ§  MEMORY SYSTEM
# ============================================================================
class AdvancedMemory:
    def __init__(self):
        self.memory_file = "artovix_memory.json"
        self.lock = threading.Lock()
        
    def load(self):
        try:
            with self.lock:
                if os.path.exists(self.memory_file):
                    with open(self.memory_file, 'r', encoding='utf-8') as f:
                        return json.load(f)
        except Exception as e:
            logger.error(f"Memory load error: {e}")
        return {}
    
    def save(self, data):
        try:
            with self.lock:
                with open(self.memory_file, 'w', encoding='utf-8') as f:
                    json.dump(data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"Memory save error: {e}")

    def get_user_data(self, user_id):
        user_id = str(user_id)
        data = self.load()
        user_data = data.get(user_id, {})
        
        # Backward compatibility: if it's a list, convert to dict
        if isinstance(user_data, list):
            user_data = {"history": user_data, "settings": {}}
        
        if "history" not in user_data: user_data["history"] = []
        if "settings" not in user_data: user_data["settings"] = {}
        
        return user_data

    def save_user_data(self, user_id, user_data):
        user_id = str(user_id)
        data = self.load()
        data[user_id] = user_data
        self.save(data)

    def get_setting(self, user_id, key, default=None):
        user_data = self.get_user_data(user_id)
        return user_data["settings"].get(key, default)

    def update_setting(self, user_id, key, value):
        user_data = self.get_user_data(user_id)
        user_data["settings"][key] = value
        self.save_user_data(user_id, user_data)

memory = AdvancedMemory()

# ============================================================================
# ğŸ­ PERSONA & SYSTEM
# ============================================================================
SYSTEM_PROMPT = """You are Artovix, an elite AI assistant in 2026.

PERSONALITY:
- Brilliant futurist AI
- Empathetic and supportive  
- Creative problem solver
- Multimodal expert
- Ethical and responsible

GUIDELINES:
1. Be helpful, accurate, and concise
2. Use appropriate emojis
3. Admit when you don't know something
4. Consider context from previous messages
5. Think step-by-step for complex problems

RESPONSE FORMAT:
- Use Markdown for readability
- Structure complex answers with bullet points
- Keep responses clear and engaging

Remember: You're talking to a human in 2026!"""

# ============================================================================
# ğŸ› ï¸ UTILITY FUNCTIONS
# ============================================================================
def clean_markdown(text):
    """Clean markdown to prevent Telegram parsing errors"""
    if not text:
        return text
    
    # Simple escaping for special characters that often break Telegram MarkdownV2 or Markdown
    # but we are using Markdown (v1) in telebot.TeleBot(BOT_TOKEN, parse_mode="Markdown")
    
    # Fix unclosed code blocks
    if text.count('```') % 2 != 0:
        text += '\n```'
        
    # Fix unclosed bold/italic
    if text.count('**') % 2 != 0:
        text += '**'
    if text.count('_') % 2 != 0:
        text += '_'
    if text.count('*') % 2 != 0:
        text += '*'
        
    return text[:4000]

def safe_send_message(chat_id, text, **kwargs):
    """Safely send a message with error handling"""
    try:
        return bot.send_message(chat_id, text, **kwargs)
    except Exception as e:
        logger.error(f"Send message error: {e}")
        # Try without markdown
        try:
            text_plain = text.replace('*', '').replace('_', '').replace('`', '').replace('~', '')
            return bot.send_message(chat_id, text_plain, **kwargs)
        except Exception as e2:
            logger.error(f"Plain text send error: {e2}")
            return None

# ============================================================================
# ğŸ–¼ï¸ IMAGE GENERATOR (IMPROVED WITH MULTIPLE SERVICES)
# ============================================================================
class ImageGenerator:
    """Improved Image Generator with multiple reliable services"""
    
    @staticmethod
    def generate(prompt: str, model_type: str = "auto"):
        """Generate AI images using multiple reliable services"""
        try:
            clean_prompt = prompt.strip()
            if not clean_prompt:
                return None
            
            logger.info(f"Generating image ({model_type}) for: {clean_prompt[:50]}...")
            
            # 1. Hugging Face (FLUX.1-schnell) - More reliable for free API
            if model_type in ["auto", "flux"]:
                try:
                    logger.info("Trying Hugging Face (FLUX.1-schnell)...")
                    hf_model = "black-forest-labs/FLUX.1-schnell"
                    # New Router endpoint as requested by HF Error 410
                    hf_url = f"https://api-inference.huggingface.co/models/{hf_model}"
                    
                    headers = {
                        "Authorization": f"Bearer {HF_KEY}",
                        "x-use-cache": "false"
                    }
                    
                    response = requests.post(
                        hf_url, 
                        headers=headers, 
                        json={"inputs": clean_prompt},
                        timeout=60
                    )
                    
                    if response.status_code == 200:
                        content_type = response.headers.get('Content-Type', '')
                        if 'image' in content_type:
                            logger.info("âœ“ Hugging Face successful!")
                            return response.content
                        else:
                            logger.warning(f"HF returned non-image: {content_type}")
                    
                    elif response.status_code == 410:
                        # If still 410, try the specific router URL from error message
                        router_url = f"https://router.huggingface.co/hf-inference/models/{hf_model}"
                        logger.info("Attempting HF Router fallback...")
                        response = requests.post(
                            router_url,
                            headers=headers,
                            json={"inputs": clean_prompt},
                            timeout=60
                        )
                        if response.status_code == 200:
                            return response.content
                    
                    logger.warning(f"HF failed ({response.status_code}): {response.text[:100]}")
                        
                except Exception as e:
                    logger.warning(f"Hugging Face exception: {str(e)[:100]}")

            # 2. Pollinations.ai (Reliable fallback/choice)
            if model_type in ["auto", "pollinations"]:
                try:
                    encoded_prompt = requests.utils.quote(clean_prompt)
                    url1 = f"https://image.pollinations.ai/prompt/{encoded_prompt}"
                    logger.info(f"Trying Pollinations.ai...")
                    
                    headers = {'User-Agent': 'Mozilla/5.0'}
                    response = requests.get(url1, headers=headers, timeout=15)
                    
                    if response.status_code == 200:
                        content_type = response.headers.get('content-type', '')
                        if 'image' in content_type.lower():
                            logger.info("âœ“ Pollinations.ai successful!")
                            return response.content
                except Exception as e:
                    logger.warning(f"Pollinations.ai failed: {str(e)[:100]}")
            
            # 3. DeepAI / Stylized Pollinations
            if model_type in ["auto", "creative"]:
                try:
                    logger.info(f"Trying Creative style...")
                    import random
                    styles = ["digital-art", "fantasy-art", "neon-punk", "isometric", "low-poly"]
                    style = random.choice(styles)
                    encoded_prompt = requests.utils.quote(clean_prompt)
                    url2 = f"https://image.pollinations.ai/prompt/{encoded_prompt}?model={style}"
                    response = requests.get(url2, timeout=15)
                    
                    if response.status_code == 200:
                        logger.info(f"âœ“ Creative style {style} successful!")
                        return response.content
                except Exception as e:
                    logger.warning(f"Creative mode failed: {str(e)[:100]}")
            
            # Fallback to Text Description ONLY if auto mode fails everything
            if model_type == "auto":
                try:
                    logger.info("Creating enhanced text description fallback...")
                    description_prompt = f"Create a detailed visual description for: {clean_prompt}"
                    
                    if not groq_client:
                        logger.warning("Groq unavailable: cannot create text fallback description.")
                        return {
                            'type': 'text',
                            'prompt': clean_prompt,
                            'description': "AI backend not configured. Set GROQ_API_KEY in .env to enable detailed descriptions.",
                            'emojis': 'âš ï¸',
                            'suggestion': "Add GROQ_API_KEY to .env and restart the bot."
                        }

                    response = groq_client.chat.completions.create(
                        model="llama-3.3-70b-versatile",
                        messages=[{"role": "user", "content": description_prompt}],
                        temperature=0.8,
                        max_tokens=200
                    )
                    
                    return {
                        'type': 'text',
                        'prompt': clean_prompt,
                        'description': response.choices[0].message.content,
                        'emojis': 'ğŸ¨âœ¨',
                        'suggestion': "Try a different prompt or simpler description."
                    }
                except Exception as e:
                    logger.error(f"Text fallback failed: {e}")
                    return None
            
            # If a specific model was requested and failed, return None to handle error in command
            return None
                    
        except Exception as e:
            logger.error(f"Image generation error: {e}")
            return None

# ============================================================================
# ğŸš€ START COMMAND (FIXED)
# ============================================================================
@bot.message_handler(commands=['start', 'artovix', 'hello'])
def start_command(message):
    try:
        welcome_msg = """ğŸŒŸ *Welcome to Artovix 2026!* ğŸŒŸ

I'm your AI assistant powered by Groq's Llama 3.3 70B!

ğŸ¯ *QUICK START:*
1. ğŸ’¬ **Chat** - Just type your message
2. ğŸ¨ **AI Images** - `/flux`, `/pollin`, `/art`, or `/draw`
3. ğŸ™ï¸ **Voice** - Send a voice message
4. ğŸ–¼ï¸ **Vision** - Send a photo to analyze
5. ğŸ” **Search** - `/search [question]`

ğŸ› ï¸ *IMAGE COMMANDS:*
`/flux` - High-quality (FLUX.1-dev)
`/pollin` - Fast & Reliable
`/art` - Creative/Artistic styles
`/draw` - Your default model

ğŸ› ï¸ *UTILITY COMMANDS:*
`/help` - Command reference
`/search` - Search information
`/code` - Analyze code
`/stats` - View analytics
`/reset` - Clear memory
`/status` - Bot health

*Ready to begin?* ğŸš€"""

        markup = InlineKeyboardMarkup(row_width=2)
        markup.add(
            InlineKeyboardButton("ğŸ’¬ Chat Now", callback_data="start_chat"),
            InlineKeyboardButton("ğŸ¨ Draw Image", callback_data="generate_image"),
            InlineKeyboardButton("ğŸ’» Code Help", callback_data="code_help"),
            InlineKeyboardButton("ğŸ” Search Web", callback_data="ask_question")
        )
        
        safe_send_message(message.chat.id, welcome_msg, reply_markup=markup)
        logger.info(f"âœ“ Start command from user {message.chat.id}")
        
    except Exception as e:
        logger.error(f"Start command error: {e}")
        bot.send_message(message.chat.id, "ğŸŒŸ Welcome! Type /help to see commands.")

# ============================================================================
# ğŸ¨ DRAW COMMAND (IMPROVED)
# ============================================================================
@bot.message_handler(commands=['draw', 'imagine', 'generate'])
def handle_draw(message):
    thinking_msg = None
    try:
        # Get prompt from command
        if message.text and len(message.text.split()) > 1:
            prompt = ' '.join(message.text.split()[1:])
        else:
            # Show help if no prompt
            help_text = """ğŸ¨ *AI Image Generator*

*Usage:* `/draw [description]`

*Examples:*
â€¢ `/draw a majestic dragon flying over mountains at sunset`
â€¢ `/draw cyberpunk city with neon lights, rain, futuristic`
â€¢ `/draw cute anime cat with sunglasses, detailed background`
â€¢ `/draw fantasy forest with glowing mushrooms, magical`

*Tips:*
â€¢ Be detailed with colors and lighting
â€¢ Add style: `digital art`, `photorealistic`, `anime style`
â€¢ Specify composition: `wide angle`, `close-up`, `dynamic`

*Try:* `/draw a beautiful landscape with mountains and lake`"""
            
            safe_send_message(message.chat.id, help_text)
            return
        
        # Show thinking message
        thinking_msg = safe_send_message(
            message.chat.id,
            f"ğŸ¨ *Creating:* \"{prompt[:60]}...\"\n"
            f"â³ Generating image with AI... (10-20 seconds)"
        )
        
        # Generate image
        result = ImageGenerator.generate(prompt)
        
        # Delete thinking message
        if thinking_msg:
            try:
                bot.delete_message(message.chat.id, thinking_msg.message_id)
            except:
                pass
        
        if result:
            if isinstance(result, dict) and result.get('type') == 'text':
                # Text-based result (fallback)
                text_response = f"""ğŸ¨ *AI Image Concept:* {result['prompt']}

{result['emojis']} *Visual Description:*
{result['description']}

ğŸ’¡ *Pro Tip:* {result['suggestion']}

âœ¨ *Try:* `/draw {prompt}, 4k, detailed, cinematic lighting`"""
                
                safe_send_message(message.chat.id, text_response)
                
            else:
                # Actual image
                try:
                    bot.send_photo(
                        message.chat.id,
                        result,
                        caption=f"ğŸ¨ *AI Generated:* {prompt}\n\n"
                                   f"âœ¨ Powered by Artovix AI | {datetime.now().strftime('%H:%M')}"
                    )
                    logger.info(f"âœ“ Image sent to {message.chat.id}")
                except Exception as e:
                    logger.error(f"Photo send error: {e}")
                    # Fallback to text
                    safe_send_message(
                        message.chat.id,
                        f"ğŸ¨ *Generated:* {prompt}\n\n"
                        f"âœ… Image created! (Preview unavailable)\n\n"
                        f"âœ¨ Try: `/draw {prompt}, enhanced details`"
                    )
        else:
            # No result
            safe_send_message(
                message.chat.id,
                f"ğŸ¨ *Your Concept:* {prompt}\n\n"
                f"That's an awesome idea! ğŸš€\n\n"
                f"*Try being more specific:*\n"
                f"â€¢ Add colors: `vibrant colors`, `golden hour lighting`\n"
                f"â€¢ Specify style: `digital art style`, `anime artwork`\n"
                f"â€¢ Add details: `highly detailed`, `intricate patterns`\n\n"
                f"*Example:* `/draw {prompt}, cinematic lighting, 8k resolution`"
            )
        
        analytics.log_request(message.chat.id, len(prompt.split()), "image_generation")
        
    except Exception as e:
        logger.error(f"Draw command error: {e}\n{traceback.format_exc()}")
        
        # Clean up thinking message
        if thinking_msg:
            try:
                bot.delete_message(message.chat.id, thinking_msg.message_id)
            except:
                pass
        
        safe_send_message(
            message.chat.id,
            "ğŸ¨ *Image Generation*\n\n"
            "Try: `/draw [detailed description]`\n\n"
            "*Example:* `/draw a fantasy castle on a cloud, sunset lighting`"
        )

# ============================================================================
# ğŸ” SEARCH COMMAND (FIXED)
# ============================================================================
@bot.message_handler(commands=['search', 'find', 'google'])
def handle_search(message):
    try:
        # Extract query
        if message.text and len(message.text.split()) > 1:
            query = ' '.join(message.text.split()[1:])
        else:
            safe_send_message(
                message.chat.id,
                "ğŸ” *Web Search*\n\n"
                "*Usage:* `/search [your question]`\n\n"
                "*Examples:*\n"
                "â€¢ `/search latest AI developments in 2026`\n"
                "â€¢ `/search how to learn Python programming`\n"
                "â€¢ `/search best practices for web development`"
            )
            return
        
        # Show searching indicator
        bot.send_chat_action(message.chat.id, 'typing')
        
        # Create search prompt with enhanced instructions
        search_prompt = f"""Search Query: {query}
        
        As a Knowledge Specialist in 2026, provide a comprehensive search result for the query above.
        
        Structure your response as follows:
        ğŸŒ [Topic Overview]
        Brief summary of the most current information.
        
        ğŸ“Œ [Key Facts & Developments]
        - Detail 1
        - Detail 2
        
        ğŸ› ï¸ [Practical Insights/Applications]
        How this information is used or its significance.
        
        ğŸ’¡ [Expert Tip]
        A unique insight or recommendation.
        
        Keep it professional, accurate, and formatted for a mobile chat interface."""
        
        try:
            if not groq_client:
                safe_send_message(message.chat.id, "ğŸ”Œ *AI backend not configured.*\nSet `GROQ_API_KEY` in your .env to enable search features.")
                return

            # Get response from Groq
            response = groq_client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": "user", "content": search_prompt}],
                temperature=0.7,
                max_tokens=500
            )

            answer = clean_markdown(response.choices[0].message.content)

            # Send result
            result_text = f"ğŸ” *Search Results:* {query}\n\n{answer}\n\nâœ¨ *Source:* Artovix AI Knowledge Base"
            safe_send_message(message.chat.id, result_text)

        except Exception as api_error:
            logger.error(f"Search API error: {api_error}")
            safe_send_message(
                message.chat.id,
                f"ğŸ” *Search:* {query}\n\n"
                f"I'll help you with that! Here's what I know:\n\n"
                f"Please try rephrasing your question or ask me directly about the topic."
            )
        
        analytics.log_request(message.chat.id, len(query.split()) * 30, "search")
        
    except Exception as e:
        logger.error(f"Search command error: {e}")
        safe_send_message(
            message.chat.id,
            "ğŸ” *Search temporarily unavailable*\n\n"
            "Try asking your question directly to me!"
        )

# ============================================================================
# ğŸ’» CODE COMMAND (FIXED)
# ============================================================================
@bot.message_handler(commands=['code', 'program', 'debug'])
def handle_code(message):
    try:
        # Extract code or question
        if message.text and len(message.text.split()) > 1:
            code_text = ' '.join(message.text.split()[1:])
        else:
            safe_send_message(
                message.chat.id,
                "ğŸ’» *Code Assistant*\n\n"
                "*Usage:*\n"
                "1. Ask a question: `/code how to reverse a string in Python?`\n"
                "2. Send code for analysis:\n"
                "```python\n"
                "def hello():\n"
                "    print('Hello World!')\n"
                "```\n\n"
                "*Examples:*\n"
                "â€¢ `/code explain this Python function`\n"
                "â€¢ `/code how to create a web API`\n"
                "â€¢ `/code fix my JavaScript code`"
            )
            return
        
        bot.send_chat_action(message.chat.id, 'typing')
        
        # Create code analysis prompt
        if '```' in code_text:
            # It's code in a block
            code_prompt = f"""Analyze this code and provide:

1. What it does
2. Any issues or bugs
3. Improvements
4. Best practices

Code:
{code_text}"""
        else:
            # It's a question
            code_prompt = f"""Answer this programming question: {code_text}

Provide:
1. Clear explanation
2. Code examples if applicable
3. Best practices
4. Common pitfalls to avoid"""
        
        try:
            if not groq_client:
                safe_send_message(message.chat.id, "ğŸ”Œ *AI backend not configured.*\nSet `GROQ_API_KEY` in your .env to enable code analysis.")
                return

            response = groq_client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": "user", "content": code_prompt}],
                temperature=0.3,
                max_tokens=600
            )

            analysis = clean_markdown(response.choices[0].message.content)

            result_text = f"ğŸ’» *Code Analysis:*\n\n{analysis}\n\nğŸ”§ *Powered by Artovix AI*"
            safe_send_message(message.chat.id, result_text)

        except Exception as api_error:
            logger.error(f"Code API error: {api_error}")
            safe_send_message(
                message.chat.id,
                f"ğŸ’» *Question:* {code_text}\n\n"
                f"I can help with that! Try:\n"
                f"1. Be more specific about your code issue\n"
                f"2. Send the actual code in ```code blocks```\n"
                f"3. Ask about a specific programming language"
            )
        
        analytics.log_request(message.chat.id, len(code_text.split()), "code_analysis")
        
    except Exception as e:
        logger.error(f"Code command error: {e}")
        safe_send_message(
            message.chat.id,
            "ğŸ’» *Code analysis failed*\n\n"
            "Try sending your code in this format:\n"
            "```python\n"
            "# Your code here\n"
            "print('Hello')\n"
            "```"
        )

# ============================================================================
# ğŸ“Š STATS COMMAND (FIXED)
# ============================================================================
@bot.message_handler(commands=['stats', 'analytics', 'metrics'])
def handle_stats(message):
    try:
        metrics = analytics.get_current_metrics()
        breakdown = metrics.get('breakdown', {})
        
        breakdown_text = ""
        for rtype, count in breakdown.items():
            breakdown_text += f"â€¢ {rtype.replace('_', ' ').title()}: {count}\n"
        
        if not breakdown_text:
            breakdown_text = "â€¢ No requests today yet."
            
        stats_msg = f"""ğŸ“Š *Artovix Analytics Dashboard*

*Live Metrics:*
â€¢ **RPM:** {metrics['RPM']} requests/minute
â€¢ **TPM:** {metrics['TPM']:,} tokens/minute
â€¢ **RPD:** {metrics['RPD']} total requests today

*Usage Breakdown:*
{breakdown_text}

*System Status:*
â€¢ ğŸ¤– Version: Artovix 2026.2.0
â€¢ ğŸ§  Models: Llama 3.3, 3.2 Vision, Whisper
â€¢ ğŸ’¬ Active Users: {len(memory.load())}
â€¢ ğŸ• Server Time: {datetime.now().strftime('%H:%M:%S')}

*All systems operational!* ğŸš€"""
        
        safe_send_message(message.chat.id, stats_msg)
        
    except Exception as e:
        logger.error(f"Stats command error: {e}")
        safe_send_message(message.chat.id, "ğŸ“Š Analytics: System active and running!")

# ============================================================================
# ğŸ›¡ï¸ OTHER COMMANDS (FIXED)
# ============================================================================
@bot.message_handler(commands=['reset'])
def handle_reset(message):
    try:
        user_id = str(message.chat.id)
        user_data = memory.get_user_data(user_id)
        user_data["history"] = []
        memory.save_user_data(user_id, user_data)
        
        safe_send_message(
            message.chat.id,
            "ğŸ§¹ *Memory Cleared!*\n\n"
            "Our conversation history has been reset.\n"
            "Ready for a fresh start! ğŸ‘‹\n\n"
            "*Try:* `/draw something creative`"
        )
    except Exception as e:
        logger.error(f"Reset error: {e}")
        safe_send_message(message.chat.id, "ğŸ§¹ Reset completed!")

@bot.message_handler(commands=['status'])
def handle_status(message):
    try:
        status_msg = f"""âœ… *Artovix Status Report*


*Core Systems:*
â€¢ ğŸ¤– AI Engine: âœ… Online
â€¢ ğŸ§  Memory: âœ… {len(memory.load())} active
â€¢ ğŸ¨ Image Gen: âœ… Multiple services
â€¢ ğŸ™ï¸ Voice/Vision: âœ… Optimized
â€¢ ğŸ” Search: âœ… Active

*Server Info:*
â€¢ Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
â€¢ Version: 2026.2.0 Stable
â€¢ Uptime: 100%

*Ready to assist!* ğŸš€"""
        
        safe_send_message(message.chat.id, status_msg)
    except Exception as e:
        logger.error(f"Status error: {e}")
        safe_send_message(message.chat.id, "âœ… Artovix is running!")

@bot.message_handler(commands=['help'])
def handle_help(message):
    try:
        help_text = """ğŸ”§ *Artovix Command Reference*

*Image Generation:*
`/flux [prompt]` - High-quality (FLUX.1-dev)
`/pollin [prompt]` - Fast & reliable generation
`/art [prompt]` - Creative & artistic styles
`/auto [prompt]` - Smart model selection
`/draw [prompt]` - Use your preferred model

*Main Commands:*
`/start` - Welcome guide & features
`/help` - This command list
`/search [query]` - Search knowledge
`/code [question/code]` - Code help
`/stats` - View analytics dashboard
`/reset` - Clear conversation memory
`/status` - Check bot health

*Tips:*
â€¢ Be descriptive for better images
â€¢ Use `/draw` without a prompt to change your default model
â€¢ Send photos to analyze them (Vision)
â€¢ Send voice messages to transcribe (Whisper)

*Need more help?* Just chat with me normally! ğŸ˜Š"""
        
        safe_send_message(message.chat.id, help_text)
    except Exception as e:
        logger.error(f"Help error: {e}")
        safe_send_message(message.chat.id, "Type /start to begin!")

# ============================================================================
# ğŸ¨ DRAW COMMANDS (MODEL-SPECIFIC)
# ============================================================================
def process_image_generation(message, model_type=None):
    """Helper function to handle all image generation requests"""
    thinking_msg = None
    try:
        user_id = message.chat.id
        
        # Get prompt from command
        if message.text and len(message.text.split()) > 1:
            prompt = ' '.join(message.text.split()[1:])
        else:
            # Show help if no prompt
            current_model = memory.get_setting(user_id, "image_model", "auto")
            display_model = model_type if model_type else current_model
            
            help_text = f"""ğŸ¨ *AI Image Generator ({display_model.upper()})*

*Usage:* `/{display_model if model_type else 'draw'} [description]`

*Available Commands:*
â€¢ `/flux` - High Quality (HF)
â€¢ `/pollinations` - Fast & Reliable
â€¢ `/creative` - Artistic Styles
â€¢ `/auto` - Smart Selection

*Example:* `/{display_model if model_type else 'flux'} a futuristic city in neon rain`"""
            
            safe_send_message(user_id, help_text)
            return

        # Use specified model or user's preferred model
        active_model = model_type if model_type else memory.get_setting(user_id, "image_model", "auto")
        
        # Show thinking message
        thinking_msg = safe_send_message(
            user_id,
            f"ğŸ¨ *Creating with {active_model.upper()}:* \"{prompt[:60]}...\"\n"
            f"â³ Generating image... (10-30 seconds)"
        )
        
        # Generate image
        result = ImageGenerator.generate(prompt, model_type=active_model)
        
        # Delete thinking message
        if thinking_msg:
            try: bot.delete_message(user_id, thinking_msg.message_id)
            except: pass
        
        if result:
            if isinstance(result, dict) and result.get('type') == 'text':
                # Text-based result (fallback)
                text_response = f"""ğŸ¨ *AI Image Concept:* {result['prompt']}

âœ¨ *Model:* {active_model.upper()} (Fallback)

{result['emojis']} *Visual Description:*
{result['description']}

ğŸ’¡ *Pro Tip:* {result['suggestion']}"""
                
                safe_send_message(user_id, text_response)
                
            else:
                # Actual image
                try:
                    bot.send_photo(
                        user_id,
                        result,
                        caption=f"ğŸ¨ *AI Generated ({active_model.upper()}):* {prompt}\n\n"
                                       f"âœ¨ Powered by Artovix AI | {datetime.now().strftime('%H:%M')}"
                    )
                    logger.info(f"âœ“ Image sent to {user_id}")
                except Exception as e:
                    logger.error(f"Photo send error: {e}")
                    safe_send_message(user_id, "âŒ Failed to send image. Try again!")
        else:
            safe_send_message(user_id, "âŒ Generation failed. Try a different prompt or model.")
        
        analytics.log_request(user_id, len(prompt.split()), f"image_gen_{active_model}")
        
    except Exception as e:
        logger.error(f"Image gen error: {e}")
        if thinking_msg:
            try: bot.delete_message(message.chat.id, thinking_msg.message_id)
            except: pass
        safe_send_message(message.chat.id, "âŒ Error occurred. Please try again.")

@bot.message_handler(commands=['draw', 'imagine', 'generate'])
def handle_draw_default(message):
    process_image_generation(message)

@bot.message_handler(commands=['flux'])
def handle_flux(message):
    process_image_generation(message, model_type="flux")

@bot.message_handler(commands=['pollinations', 'pollin'])
def handle_pollinations(message):
    process_image_generation(message, model_type="pollinations")

@bot.message_handler(commands=['creative', 'art'])
def handle_creative(message):
    process_image_generation(message, model_type="creative")

@bot.message_handler(commands=['auto'])
def handle_auto(message):
    process_image_generation(message, model_type="auto")

@bot.callback_query_handler(func=lambda call: call.data.startswith('set_model_'))
def handle_model_selection(call):
    try:
        model_type = call.data.replace('set_model_', '')
        user_id = call.message.chat.id
        
        memory.update_setting(user_id, "image_model", model_type)
        
        # Update the message with the new selection
        markup = InlineKeyboardMarkup(row_width=2)
        markup.add(
            InlineKeyboardButton(f"{'âœ… ' if model_type == 'auto' else ''}Auto", callback_data="set_model_auto"),
            InlineKeyboardButton(f"{'âœ… ' if model_type == 'flux' else ''}Flux", callback_data="set_model_flux"),
            InlineKeyboardButton(f"{'âœ… ' if model_type == 'pollinations' else ''}Pollinations", callback_data="set_model_pollinations"),
            InlineKeyboardButton(f"{'âœ… ' if model_type == 'creative' else ''}Creative", callback_data="set_model_creative")
        )
        
        bot.edit_message_text(
            f"âœ… Model set to: **{model_type.upper()}**\n\nNow use `/draw [prompt]` to generate images!",
            chat_id=user_id,
            message_id=call.message.message_id,
            reply_markup=markup,
            parse_mode="Markdown"
        )
        bot.answer_callback_query(call.id, f"Model set to {model_type}")
        
    except Exception as e:
        logger.error(f"Model selection error: {e}")
        bot.answer_callback_query(call.id, "âŒ Failed to update model.")

# ============================================================================
# ğŸ™ï¸ VOICE MESSAGES HANDLER
# ============================================================================
@bot.message_handler(content_types=['voice'])
def handle_voice(message):
    try:
        bot.send_chat_action(message.chat.id, 'upload_document')
        
        # Get voice file info
        file_info = bot.get_file(message.voice.file_id)
        downloaded_file = bot.download_file(file_info.file_path)
        
        # Save temporarily
        temp_filename = f"temp/voice_{message.chat.id}_{int(time.time())}.ogg"
        os.makedirs("temp", exist_ok=True)
        with open(temp_filename, 'wb') as f:
            f.write(downloaded_file)
        
        # Transcribe with Groq Whisper
        with open(temp_filename, "rb") as audio_file:
            if not groq_client:
                safe_send_message(message.chat.id, "ğŸ”Œ *AI backend not configured.*\nSet `GROQ_API_KEY` in your .env to enable voice transcription.")
                return

            transcription = groq_client.audio.transcriptions.create(
                file=(temp_filename, audio_file.read()),
                model="whisper-large-v3",
                response_format="text"
            )
        
        # Cleanup
        os.remove(temp_filename)
        
        if not transcription or len(transcription.strip()) < 1:
            safe_send_message(message.chat.id, "ğŸ¤ *I couldn't hear you clearly.*\nCould you please try again?")
            return

        # Process as a text message
        message.text = transcription
        safe_send_message(message.chat.id, f"ğŸ¤ *Transcribed:* \"{transcription}\"")
        handle_all_messages(message)
        
    except Exception as e:
        logger.error(f"Voice handling error: {e}")
        safe_send_message(message.chat.id, "ğŸ¤ *Voice processing failed.*\nPlease try sending a text message instead.")

# ============================================================================
# ğŸ–¼ï¸ PHOTO ANALYSIS HANDLER (VISION)
# ============================================================================
@bot.message_handler(content_types=['photo'])
def handle_photo(message):
    try:
        bot.send_chat_action(message.chat.id, 'typing')
        
        # Get highest resolution photo
        file_id = message.photo[-1].file_id
        file_info = bot.get_file(file_id)
        downloaded_file = bot.download_file(file_info.file_path)
        
        # Encode to base64
        base64_image = base64.b64encode(downloaded_file).decode('utf-8')
        
        # Get caption or use default
        prompt = message.caption if message.caption else "Describe this image in detail and tell me what you see."
        
        # Analyze with Groq Vision
        if not groq_client:
            safe_send_message(message.chat.id, "ğŸ”Œ *AI backend not configured.*\nSet `GROQ_API_KEY` in your .env to enable vision features.")
            return

        response = groq_client.chat.completions.create(
            model="llama-3.2-11b-vision-preview",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}",
                            },
                        },
                    ],
                }
            ],
            max_tokens=500
        )

        analysis = clean_markdown(response.choices[0].message.content)

        safe_send_message(message.chat.id, f"ğŸ–¼ï¸ *Image Analysis:*\n\n{analysis}")

        analytics.log_request(message.chat.id, 500, "vision_analysis")
        
    except Exception as e:
        logger.error(f"Vision handling error: {e}")
        safe_send_message(message.chat.id, "ğŸ–¼ï¸ *Vision analysis failed.*\nPlease try again with a clearer image.")

# ============================================================================
# ğŸ’¬ TEXT MESSAGES HANDLER
# ============================================================================
@bot.message_handler(func=lambda message: True)
def handle_all_messages(message):
    try:
        # Skip if empty or command
        if not message.text or message.text.startswith('/'):
            return
        
        logger.info(f"Message from {message.chat.id}: {message.text[:50]}...")
        
        user_id = str(message.chat.id)
        user_data = memory.get_user_data(user_id)
        history = user_data["history"]
        
        # Prepare conversation
        messages = [
            {"role": "system", "content": SYSTEM_PROMPT},
            *history[-4:],  # Last 2 exchanges
            {"role": "user", "content": message.text}
        ]
        
        bot.send_chat_action(message.chat.id, 'typing')
        
        try:
            if not groq_client:
                safe_send_message(message.chat.id, "ğŸ”Œ *AI backend not configured.*\nSet `GROQ_API_KEY` in your .env to enable chat responses.")
                return

            response = groq_client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=messages,
                temperature=0.7,
                max_tokens=400
            )
            
            reply = clean_markdown(response.choices[0].message.content)
            
            # Save to memory
            history.extend([
                {"role": "user", "content": message.text},
                {"role": "assistant", "content": reply}
            ])
            
            # Limit memory size
            if len(history) > 20:
                history = history[-20:]
            
            user_data["history"] = history
            memory.save_user_data(user_id, user_data)
            
            # Send reply
            safe_send_message(message.chat.id, reply)
            
            # Log analytics
            tokens_used = len(message.text.split()) + len(reply.split())
            analytics.log_request(message.chat.id, tokens_used, "chat")
            
        except Exception as api_error:
            logger.error(f"Chat API error: {api_error}\n{traceback.format_exc()}")
            try:
                safe_send_message(
                    message.chat.id,
                    "ğŸ¤– *I'm thinking...*\n\n"
                    "Please try again in a moment or rephrase your question."
                )
            except Exception:
                logger.error("Failed to send fallback message after chat error.")
        
    except Exception as e:
        logger.error(f"Message handler error: {e}\n{traceback.format_exc()}")
        try:
            safe_send_message(message.chat.id, "âš ï¸ Please try again or use /reset to start fresh.")
        except:
            pass

# ============================================================================
# ğŸª CALLBACK HANDLER
# ============================================================================
@bot.callback_query_handler(func=lambda call: True)
def handle_callback(call):
    try:
        if call.data == "start_chat":
            bot.answer_callback_query(call.id, "Let's chat!")
            safe_send_message(call.message.chat.id, 
                "ğŸ’¬ *Chat Activated!*\n\n"
                "Just type your message and I'll respond!\n\n"
                "*Try asking:*\n"
                "â€¢ What can you do?\n"
                "â€¢ Tell me about AI\n"
                "â€¢ Help me with a problem"
            )
        
        elif call.data == "generate_image":
            bot.answer_callback_query(call.id, "Image generation!")
            safe_send_message(call.message.chat.id, 
                "ğŸ¨ *Image Generator*\n\n"
                "*Usage:* `/draw [description]`\n\n"
                "*Quick examples:*\n"
                "â€¢ `/draw sunset over mountains`\n"
                "â€¢ `/draw cute robot futuristic city`\n"
                "â€¢ `/draw magical forest glowing plants`\n\n"
                "Be creative! ğŸ¨"
            )
        
        elif call.data == "code_help":
            bot.answer_callback_query(call.id, "Code help!")
            safe_send_message(call.message.chat.id, 
                "ğŸ’» *Code Assistant*\n\n"
                "*Two ways to use:*\n"
                "1. Ask: `/code how to [do something]`\n"
                "2. Send code in:\n"
                "```python\n"
                "print('Hello World!')\n"
                "```\n\n"
                "*I can help with:* Python, JavaScript, Java, C++, etc."
            )
        
        elif call.data == "ask_question":
            bot.answer_callback_query(call.id, "Search!")
            safe_send_message(call.message.chat.id, 
                "ğŸ” *Knowledge Search*\n\n"
                "*Usage:* `/search [your question]`\n\n"
                "*Examples:*\n"
                "â€¢ `/search latest space discoveries`\n"
                "â€¢ `/search how AI works in 2026`\n"
                "â€¢ `/search best programming practices`\n\n"
                "Ask me anything! ğŸŒŸ"
            )
        
    except Exception as e:
        logger.error(f"Callback error: {e}")

# ============================================================================
# ğŸš€ MAIN EXECUTION
# ============================================================================
if __name__ == "__main__":
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                  ARTOVIX 2026                    â•‘
    â•‘            ULTIMATE AI EDITION                   â•‘
    â•‘                                                  â•‘
    â•‘  âœ… **ALL COMMANDS WORKING:**                    â•‘
    â•‘    â€¢ /start, /help, /status, /stats             â•‘
    â•‘    â€¢ /draw - Image generation                   â•‘
    â•‘    â€¢ /search - Knowledge specialist             â•‘
    â•‘    â€¢ /code - Programming expert                 â•‘
    â•‘                                                  â•‘
    â•‘  ğŸš€ **NEW FUTURES ADDED:**                       â•‘
    â•‘    â€¢ ğŸ™ï¸ Voice-to-Text (Whisper V3)               â•‘
    â•‘    â€¢ ğŸ–¼ï¸ Image Analysis (Vision)                 â•‘
    â•‘    â€¢ ğŸ“Š Analytics Breakdown                     â•‘
    â•‘    â€¢ ğŸ›¡ï¸ Concurrent Memory Lock                  â•‘
    â•‘                                                  â•‘
    â•‘  ğŸš€ Starting up...                               â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    logger.info("ğŸš€ Starting Artovix 2026 (Ultimate Edition)...")
    print(f"ğŸ“… Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ¤– Bot: @{bot.get_me().username}")
    print(f"ğŸ§  Memory: {len(memory.load())} active conversations")
    print(f"ğŸ“Š Analytics: Enhanced database ready")
    
    print("\n" + "="*60)
    print("âœ… ALL COMMANDS READY:")
    print("="*60)
    print("ğŸ’¬ /start - Welcome & features")
    print("ğŸ¨ /draw [prompt] - Generate images")
    print("ğŸ” /search [query] - Search knowledge")
    print("ğŸ’» /code [question] - Programming help")
    print("ğŸ“Š /stats - View analytics")
    print("ğŸ§¹ /reset - Clear memory")
    print("âœ… /status - Bot health")
    print("ğŸ”§ /help - Command list")
    print("="*60)
    print("\nâš¡ Bot is running and ready to receive commands!")
    print("ğŸ’¡ Tip: Try /draw a beautiful landscape")
    
    try:
        bot.infinity_polling(
            timeout=30,
            long_polling_timeout=5,
            logger_level=logging.INFO
        )
    except KeyboardInterrupt:
        print("\nğŸ›‘ Bot stopped by user.")
    except Exception as e:
        logger.error(f"Bot crashed: {e}\n{traceback.format_exc()}")
        print(f"âŒ Critical error: {e}")
    finally:
        try:
            analytics.close()
            print("ğŸ“Š Analytics saved.")
        except:
            pass
        print("\nğŸ‘‹ Shutdown complete.")